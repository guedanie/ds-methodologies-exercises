{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Exercise\n",
    "\n",
    "1. Load the titanic dataset that you've put together from previous lessons.\n",
    "2. Split your data into training and test.\n",
    "3. Fit a logistic regression model on your training data using sklearn's\n",
    "   linear_model.LogisticRegression class. Use fare and pclass as the\n",
    "   predictors.\n",
    "4. Use the model's .predict method. What is the output?\n",
    "5. Use the model's .predict_proba method. What is the output? Why do you\n",
    "   think it is shaped like this?\n",
    "6. Evaluate your model's predictions on the test data set. How accurate\n",
    "   is the mode? How does changing the threshold affect this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare\n",
    "import acquire\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import split_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, test_scaled = prepare.prep_titanic(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C=1, class_weight={1:2}, random_state = 123, solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_scaled[[\"fare\", \"pclass\"]]\n",
    "y_train = train_scaled[[\"survived\"]]\n",
    "X_test = test_scaled[[\"fare\", \"pclass\"]]\n",
    "y_test = test_scaled[[\"survived\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the data into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight={1: 2}, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output here is the actual prediction it seems, on whether or not the individual is being classified likely survived or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22610689, 0.77389311],\n",
       "       [0.58623763, 0.41376237],\n",
       "       [0.5866741 , 0.4133259 ],\n",
       "       ...,\n",
       "       [0.58609211, 0.41390789],\n",
       "       [0.58665331, 0.41334669],\n",
       "       [0.58623763, 0.41376237]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output here is the probability of whether a person survived or not, and then based on a threshold of .5, it then classifies those values as a 1 or a 0. The reason why it is a two column array its becasue it is showing the probability of both predictors (fare and pclass). This means that it looks at both probabilities first independently, and then comes up with an aggregate value to predict classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.66\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions = (logit.predict_proba(X_train) >= .3).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set: 0.70\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on test set: {:.2f}'\n",
    "     .format(logit.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x122102c90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba = [i[1] for i in logit.predict_proba(X_train)]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(y_pred_proba, logit.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Exercises\n",
    "\n",
    "In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, test_scaled = prepare.prep_titanic(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoder.fit(train_scaled[[\"sex\"]])\n",
    "m = encoder.transform(train_scaled[[\"sex\"]]).todense() \n",
    "train_scaled = pd.concat([train_scaled, pd.DataFrame(m, columns=encoder.categories_[0], index=train_scaled.index)], axis = 1)\n",
    "                      \n",
    "m = encoder.transform(test_scaled[[\"sex\"]]).todense()\n",
    "test_scaled = pd.concat([test_scaled, pd.DataFrame(m, columns=encoder.categories_[0], index=test_scaled.index)], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, validate = train_test_split(train_scaled, random_state=123, train_size = .83)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create another model that includes age in addition to fare and pclass. Does this model perform better than your previous one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = train_scaled[[\"fare\", \"pclass\", \"age\"]]\n",
    "y_train_1 = train_scaled[[\"survived\"]]\n",
    "X_test_1 = validate[[\"fare\", \"pclass\", \"age\"]]\n",
    "y_test_1 = validate[[\"survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.71\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train_1, y_train_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs better than the model that only uses class and fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set: 0.66\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on test set: {:.2f}'\n",
    "     .format(logit.score(X_test_1, y_test_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_thresholds(y, probs):\n",
    "    return pd.DataFrame(\n",
    "        [evaluate_thresholds(t, y, probs) for t in np.arange(0, 1.01, 0.01)]\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_metrics_by_thresholds(y, probs, subplots=False):\n",
    "    evaluation = evaluate_thresholds(y, probs)\n",
    "    axs = (\n",
    "        evaluation.query(\"precision > 0\")\n",
    "        .set_index(\"threshold\")\n",
    "        .plot(subplots=subplots, sharex=True, sharey=True, figsize=(12, 8.5))\n",
    "    )\n",
    "    (axs[-1] if subplots else axs).set_xticks(np.arange(0, 1.05, 0.05))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_metrics_by_thresholds(y_train_1, logit.predict_proba(X_train_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Include sex in your model as well. Note that you'll need to encode this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.126353</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.050584</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.112718</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.937743</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130578</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>357</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0.579767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052521</td>\n",
       "      <td>Second</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.517510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026243</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>653</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0.452652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031630</td>\n",
       "      <td>Third</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.533074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105042</td>\n",
       "      <td>Second</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>589</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.452652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032523</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.361868</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030284</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.424125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031731</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex       age  sibsp  parch      fare  \\\n",
       "119           119         0       3  female  0.019455      4      2  0.126353   \n",
       "63             63         0       3    male  0.050584      3      2  0.112718   \n",
       "625           625         0       1    male  0.937743      0      0  0.130578   \n",
       "357           357         0       2  female  0.579767      0      0  0.052521   \n",
       "202           202         0       3    male  0.517510      0      0  0.026243   \n",
       "..            ...       ...     ...     ...       ...    ...    ...       ...   \n",
       "653           653         1       3  female  0.452652      0      0  0.031630   \n",
       "20             20         0       2    male  0.533074      0      0  0.105042   \n",
       "589           589         0       3    male  0.452652      0      0  0.032523   \n",
       "514           514         0       3    male  0.361868      0      0  0.030284   \n",
       "281           281         0       3    male  0.424125      0      0  0.031731   \n",
       "\n",
       "      class  embark_town  alone    C    Q    S  female  male  \n",
       "119   Third  Southampton      0  0.0  0.0  1.0     1.0   0.0  \n",
       "63    Third  Southampton      0  0.0  0.0  1.0     0.0   1.0  \n",
       "625   First  Southampton      1  0.0  0.0  1.0     0.0   1.0  \n",
       "357  Second  Southampton      1  0.0  0.0  1.0     1.0   0.0  \n",
       "202   Third  Southampton      1  0.0  0.0  1.0     0.0   1.0  \n",
       "..      ...          ...    ...  ...  ...  ...     ...   ...  \n",
       "653   Third   Queenstown      1  0.0  1.0  0.0     1.0   0.0  \n",
       "20   Second  Southampton      1  0.0  0.0  1.0     0.0   1.0  \n",
       "589   Third  Southampton      1  0.0  0.0  1.0     0.0   1.0  \n",
       "514   Third  Southampton      1  0.0  0.0  1.0     0.0   1.0  \n",
       "281   Third  Southampton      1  0.0  0.0  1.0     0.0   1.0  \n",
       "\n",
       "[590 rows x 16 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = train_scaled[[\"fare\", \"pclass\", \"age\", \"female\", \"male\"]]\n",
    "y_train_2 = train_scaled[[\"survived\"]]\n",
    "X_test_2= validate[[\"fare\", \"pclass\", \"age\", \"female\", \"male\"]]\n",
    "y_test_2= validate[[\"survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7762711864406779"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.819672131147541"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3 = train_scaled[[\"fare\", \"pclass\", \"age\", \"sibsp\"]]\n",
    "y_train_3 = train_scaled[[\"survived\"]]\n",
    "X_test_3= validate[[\"fare\", \"pclass\", \"age\", \"sibsp\"]]\n",
    "y_test_3= validate[[\"survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7016949152542373"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_train_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6557377049180327"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_test_3, y_test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Choose you best model and evaluate it on the test dataset. Is it overfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "\n",
    "X_train_2 = train_scaled[[\"fare\", \"pclass\", \"age\", \"female\", \"male\"]]\n",
    "y_train_2 = train_scaled[[\"survived\"]]\n",
    "X_test_2= test_scaled[[\"fare\", \"pclass\", \"age\", \"female\", \"male\"]]\n",
    "y_test_2= test_scaled[[\"survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7762711864406779"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7932960893854749"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the test with sex was our best performing model, we use it to compare it against our test data. In this case, we can see the model is not overfit, as the difference in accuracy between both is fairly small. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bonus How do different strategies for handling the missing values in the age column affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  deck  embark_town  alone  \n",
       "0        S  Third  None  Southampton      0  \n",
       "1        C  First     C    Cherbourg      0  \n",
       "2        S  Third  None  Southampton      1  \n",
       "3        S  First     C  Southampton      0  \n",
       "4        S  Third  None  Southampton      1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    714\n",
       "True     177\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.age.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(titanic, random_state = 123, train_size = .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    564\n",
       "True     148\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.age.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_avg_lookup = train.groupby([\"pclass\"]).age.agg(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"age\"] = train[\"age\"].fillna(train[\"pclass\"].map(group_avg_lookup))\n",
    "test[\"age\"] = test[\"age\"].fillna(test[\"pclass\"].map(group_avg_lookup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    712\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.age.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate = train_test_split(train, random_state =123, train_size= .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "\n",
    "X_train_4 = train[[\"fare\", \"pclass\", \"age\"]]\n",
    "y_train_4 = train[[\"survived\"]]\n",
    "X_test_4= validate[[\"fare\", \"pclass\", \"age\"]]\n",
    "y_test_4= validate[[\"survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_4, y_train_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7012302284710018"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_train_4, y_train_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6643356643356644"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_test_4, y_test_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without scaling the data, it seems the model actually performs about the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_scale_train = train[[\"age\", \"fare\"]]\n",
    "age_scale_test = test[[\"age\", \"fare\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, train_scaled, test_scaled = split_scale.min_max_scaler(age_scale_train, age_scale_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"age\"] = train_scaled[\"age\"]\n",
    "test[\"age\"] = test_scaled[\"age\"]\n",
    "train[\"fare\"] = train_scaled[\"fare\"]\n",
    "test[\"fare\"] = test_scaled[\"fare\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "\n",
    "X_train_5 = train[[\"fare\", \"pclass\", \"age\"]]\n",
    "y_train_5 = train[[\"survived\"]]\n",
    "X_test_5 = test[[\"fare\", \"pclass\", \"age\"]]\n",
    "y_test_5 = test[[\"survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_5, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7117750439367311"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_train_5, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7318435754189944"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_test_5, y_test_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even once the data is scaled, is seems to perform very similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.93217565, -0.83832614, -1.68659627]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the coefficients, we can see that they are all fairly similar, but age is definitively the most powerful indicator of suvivability at this point, and the higher the age, the lower the probability of survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bonus: How do different strategies for encoding sex affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(titanic, random_state = 123, train_size = .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>524</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>C</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>452</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7500</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.5000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>620</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>C</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "172           172         1       3  female   1.0      1      1  11.1333   \n",
       "524           524         0       3    male   NaN      0      0   7.2292   \n",
       "452           452         0       1    male  30.0      0      0  27.7500   \n",
       "170           170         0       1    male  61.0      0      0  33.5000   \n",
       "620           620         0       3    male  27.0      1      0  14.4542   \n",
       "\n",
       "    embarked  class  deck  embark_town  alone  \n",
       "172        S  Third  None  Southampton      0  \n",
       "524        C  Third  None    Cherbourg      1  \n",
       "452        C  First     C    Cherbourg      1  \n",
       "170        S  First     B  Southampton      1  \n",
       "620        C  Third  None    Cherbourg      0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = sklearn.impute.SimpleImputer(strategy = \"mean\")\n",
    "imputer.fit(train[[\"age\"]])\n",
    "train.age = imputer.transform(train[[\"age\"]])\n",
    "test.age = imputer.transform(test[[\"age\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "train[\"sex\"] = le.fit_transform(train.sex)\n",
    "test[\"sex\"] = le.transform(test.sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate = train_test_split(train, random_state = 123, train_size = .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7768014059753954"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "\n",
    "train_scaled\n",
    "\n",
    "X_train_7 = train[[\"fare\", \"pclass\", \"age\", \"sex\"]]\n",
    "y_train_7 = train[[\"survived\"]]\n",
    "X_test_7= validate[[\"fare\", \"pclass\", \"age\", \"sex\"]]\n",
    "y_test_7= validate[[\"survived\"]]\n",
    "\n",
    "logit.fit(X_train_7, y_train_7)\n",
    "\n",
    "logit.score(X_train_7, y_train_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8111888111888111"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_test_7, y_test_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00275126, -0.81985162, -0.01731668, -2.24534559]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a simple label encoder seemed to work the same as using a hot label encoder. The suprising part is that before, age was the most influencial coefficient, but once it is paired with sex, it seems that it becomes less relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. scikit-learn's LogisticRegression classifier is actually applying a regularization penalty to the coefficients by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "\n",
    "Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " When C = 0.01, then the accuracy score is 0.70\n",
      " When C = 0.1, then the accuracy score is 0.77\n",
      " When C = 1.0, then the accuracy score is 0.77\n",
      " When C = 10.0, then the accuracy score is 0.78\n",
      " When C = 100.0, then the accuracy score is 0.78\n",
      " When C = 1000.0, then the accuracy score is 0.78\n"
     ]
    }
   ],
   "source": [
    "C = .01\n",
    "c = 10\n",
    "X_train = train[[\"fare\", \"pclass\", \"sex\"]]\n",
    "y_train = train[[\"survived\"]]\n",
    "X_test = validate[[\"fare\", \"pclass\", \"sex\"]]\n",
    "y_test = validate[[\"survived\"]]\n",
    "accuracy_score = []\n",
    "\n",
    "\n",
    "for x in range(0,6):\n",
    "\n",
    "    \n",
    "    \n",
    "    logit = LogisticRegression(C=C)\n",
    "\n",
    "    logit.fit(X_train, y_train)\n",
    "\n",
    "    score = logit.score(X_train, y_train)\n",
    "    \n",
    "    accuracy_score.append(score)\n",
    "    \n",
    "    C *= c\n",
    "\n",
    "c = .001\n",
    "for i in range(1, 7):\n",
    "    print(f\" When C = {c * (10**i)}, then the accuracy score is {accuracy_score[i - 1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01008302 -0.21533558 -0.47912208]]\n",
      "[[ 7.47879367e-04 -9.40769809e-01 -2.57282771e+00]]\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(C=.01)\n",
    "\n",
    "logit.fit(X_train, y_train)\n",
    "coefficients = logit.coef_\n",
    "\n",
    "logit = LogisticRegression(C=1000)\n",
    "\n",
    "logit.fit(X_train, y_train)\n",
    "coefficients_2 = logit.coef_\n",
    "\n",
    "print(coefficients)\n",
    "print(coefficients_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire and Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.age = titanic.age.fillna(titanic.age.mean())\n",
    "titanic.age = titanic.age.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sex(df):\n",
    "    '''\n",
    "    Returns a new dataframe with the ``sex`` column encoded.\n",
    "    '''\n",
    "    return df.assign(\n",
    "        sex=(df.sex == 'female').astype(int)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = encode_sex(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(titanic, random_state = 123, train_size=.8)\n",
    "train, validate = train_test_split(train, random_state = 123, train_size = .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>535</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>573</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>736</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>34.3750</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>713</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4833</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>528</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass  sex  age  sibsp  parch     fare embarked  \\\n",
       "535           535         1       2    1    7      0      2  26.2500        S   \n",
       "573           573         1       3    1   29      0      0   7.7500        Q   \n",
       "736           736         0       3    1   48      1      3  34.3750        S   \n",
       "713           713         0       3    0   29      0      0   9.4833        S   \n",
       "528           528         0       3    0   39      0      0   7.9250        S   \n",
       "\n",
       "      class  deck  embark_town  alone  \n",
       "535  Second  None  Southampton      0  \n",
       "573   Third  None   Queenstown      1  \n",
       "736   Third  None  Southampton      0  \n",
       "713   Third  None  Southampton      1  \n",
       "528   Third  None  Southampton      1  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['pclass', 'sex', 'age', \"fare\"]]\n",
    "y_train = train[\"survived\"]\n",
    "X_validate = validate[['pclass', 'sex', 'age', \"fare\"]]\n",
    "y_validate = validate[\"survived\"]\n",
    "X_test = test[['pclass', 'sex', 'age', \"fare\"]]\n",
    "y_test = test[\"survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535    1\n",
       "573    1\n",
       "736    0\n",
       "713    0\n",
       "528    0\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame({\"actual\": y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the thing\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=123)\n",
    "\n",
    "# Fit the the thing\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate survival\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "evaluation[\"survived ~ pclass + sex + age\"] = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the probability of a survival\n",
    "\n",
    "\n",
    "y_pred_proba = clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  302   43\n",
       "1   72  152"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(titanic.survived.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(evaluation.actual, evaluation.iloc[:,1]), index = labels, columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       345\n",
      "           1       0.78      0.68      0.73       224\n",
      "\n",
      "    accuracy                           0.80       569\n",
      "   macro avg       0.79      0.78      0.78       569\n",
      "weighted avg       0.80      0.80      0.79       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import graphviz\n",
    "\n",
    "# from graphviz import Graph\n",
    "\n",
    "# dot_data = export_graphviz(clf, out_file=None) \n",
    "# graph = graphviz.Source(dot_data) \n",
    "\n",
    "# graph.render('iris_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on test set: 0.80\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run through steps 2-4 using entropy as your measure of impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the thing\n",
    "\n",
    "clf_impurity = DecisionTreeClassifier(criterion= \"gini\", max_depth=3, random_state=123)\n",
    "\n",
    "# Fit the thing\n",
    "clf_impurity.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_impurity.predict(X_train)\n",
    "evaluation[\"survived ~ pclass + sex + age (gini)\"] = clf_impurity.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.81\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf_impurity.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>296</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  296   49\n",
       "1   58  166"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(titanic.survived.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(evaluation.actual, evaluation.iloc[:,2]), index = labels, columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model survived ~ pclass + sex + age\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       345\n",
      "           1       0.78      0.68      0.73       224\n",
      "\n",
      "    accuracy                           0.80       569\n",
      "   macro avg       0.79      0.78      0.78       569\n",
      "weighted avg       0.80      0.80      0.79       569\n",
      "\n",
      "-------------\n",
      "Model survived ~ pclass + sex + age (gini)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       345\n",
      "           1       0.77      0.74      0.76       224\n",
      "\n",
      "    accuracy                           0.81       569\n",
      "   macro avg       0.80      0.80      0.80       569\n",
      "weighted avg       0.81      0.81      0.81       569\n",
      "\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,2):\n",
    "    print(f\"Model {evaluation.columns[i + 1]}\")\n",
    "    print(classification_report(evaluation.actual, evaluation.iloc[:,(i + 1)]))\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf_impurity.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we conclude that it is a pretty good model - with an accuracy of around 80%. The data is not overfitted, as the test performed relatively well. Additionally, we find that the impurity choice in this case does not have an effect on accuracy, or any of the other evaluation methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import graphviz\n",
    "\n",
    "# from graphviz import Graph\n",
    "\n",
    "# dot_data = export_graphviz(clf, out_file=None) \n",
    "# graph = graphviz.Source(dot_data) \n",
    "\n",
    "# graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Predict if someone is a smoker or not using the tips data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = data(\"tips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "1       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "2       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "3       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "4       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "5       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = tips.assign(sex=(tips.sex == 'Female').astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips[\"tip_rate\"] = tips[\"tip\"] / tips[\"total_bill\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">tip</th>\n",
       "      <th colspan=\"2\" halign=\"left\">total_bill</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tip_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>2.991854</td>\n",
       "      <td>151</td>\n",
       "      <td>19.188278</td>\n",
       "      <td>151</td>\n",
       "      <td>0.159328</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>3.008710</td>\n",
       "      <td>93</td>\n",
       "      <td>20.756344</td>\n",
       "      <td>93</td>\n",
       "      <td>0.163196</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tip       total_bill        tip_rate      \n",
       "            mean count       mean count      mean count\n",
       "smoker                                                 \n",
       "No      2.991854   151  19.188278   151  0.159328   151\n",
       "Yes     3.008710    93  20.756344    93  0.163196    93"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips.groupby(\"smoker\")[[\"tip\",\"total_bill\", \"tip_rate\"]].agg([\"mean\", \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smoker  time  \n",
       "No      Dinner    3.126887\n",
       "        Lunch     2.673778\n",
       "Yes     Dinner    3.066000\n",
       "        Lunch     2.834348\n",
       "Name: tip, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips.groupby([\"smoker\", \"time\"]).tip.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x122371f10>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=\"tip_rate\", y = \"total_bill\", data=tips, hue=\"smoker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(tips, random_state = 123, train_size=.8)\n",
    "train, validate = train_test_split(train, random_state = 123, train_size = .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"total_bill\", \"tip\", \"sex\", \"size\"]\n",
    "target = \"smoker\"\n",
    "\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_validate = validate[features]\n",
    "y_validate = validate[target]\n",
    "X_test = test[features]\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the thing\n",
    "\n",
    "clf_tips = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "\n",
    "# Fit the thing\n",
    "clf_tips.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.76\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf_tips.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     No  Yes\n",
       "No   95    4\n",
       "Yes  36   21"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, clf_tips.predict(X_train)), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.73      0.96      0.83        99\n",
      "         Yes       0.84      0.37      0.51        57\n",
      "\n",
      "    accuracy                           0.74       156\n",
      "   macro avg       0.78      0.66      0.67       156\n",
      "weighted avg       0.77      0.74      0.71       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, clf_tips.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we scale the data - does that have an impact on the outcome? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, train_scaled, test_scaled = split_scale.min_max_scaler(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tips_scaled = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "\n",
    "# Fit the thing\n",
    "clf_tips_scaled.fit(train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.63\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf_tips.score(train_scaled, y_train)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
