{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Exercise\n",
    "\n",
    "1. Load the titanic dataset that you've put together from previous lessons.\n",
    "2. Split your data into training and test.\n",
    "3. Fit a logistic regression model on your training data using sklearn's\n",
    "   linear_model.LogisticRegression class. Use fare and pclass as the\n",
    "   predictors.\n",
    "4. Use the model's .predict method. What is the output?\n",
    "5. Use the model's .predict_proba method. What is the output? Why do you\n",
    "   think it is shaped like this?\n",
    "6. Evaluate your model's predictions on the test data set. How accurate\n",
    "   is the mode? How does changing the threshold affect this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare\n",
    "import acquire\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import split_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, test_scaled = prepare.prep_titanic(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C=1, class_weight={1:2}, random_state = 123, solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_scaled[[\"fare\", \"pclass\"]]\n",
    "y_train = train_scaled[[\"survived\"]]\n",
    "X_test = test_scaled[[\"fare\", \"pclass\"]]\n",
    "y_test = test_scaled[[\"survived\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the data into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight={1: 2}, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output here is the actual prediction it seems, on whether or not the individual is being classified likely survived or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22610689, 0.77389311],\n",
       "       [0.58623763, 0.41376237],\n",
       "       [0.5866741 , 0.4133259 ],\n",
       "       ...,\n",
       "       [0.58609211, 0.41390789],\n",
       "       [0.58665331, 0.41334669],\n",
       "       [0.58623763, 0.41376237]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output here is the probability of whether a person survived or not, and then based on a threshold of .5, it then classifies those values as a 1 or a 0. The reason why it is a two column array its becasue it is showing the probability of both predictors (fare and pclass). This means that it looks at both probabilities first independently, and then comes up with an aggregate value to predict classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.66\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions = (logit.predict_proba(X_train) >= .3).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set: 0.70\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on test set: {:.2f}'\n",
    "     .format(logit.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x123c99d50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba = [i[1] for i in logit.predict_proba(X_train)]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(y_pred_proba, logit.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Exercises\n",
    "\n",
    "In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, test_scaled = prepare.prep_titanic(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoder.fit(train_scaled[[\"sex\"]])\n",
    "m = encoder.transform(train_scaled[[\"sex\"]]).todense() \n",
    "train_scaled = pd.concat([train_scaled, pd.DataFrame(m, columns=encoder.categories_[0], index=train_scaled.index)], axis = 1)\n",
    "                      \n",
    "m = encoder.transform(test_scaled[[\"sex\"]]).todense()\n",
    "test_scaled = pd.concat([test_scaled, pd.DataFrame(m, columns=encoder.categories_[0], index=test_scaled.index)], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, validate = train_test_split(train_scaled, random_state=123, train_size = .83)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create another model that includes age in addition to fare and pclass. Does this model perform better than your previous one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = train_scaled[[\"fare\", \"pclass\", \"age\"]]\n",
    "y_train_1 = train_scaled[[\"survived\"]]\n",
    "X_test_1 = validate[[\"fare\", \"pclass\", \"age\"]]\n",
    "y_test_1 = validate[[\"survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.71\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train_1, y_train_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs better than the model that only uses class and fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set: 0.66\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on test set: {:.2f}'\n",
    "     .format(logit.score(X_test_1, y_test_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_thresholds(y, probs):\n",
    "    return pd.DataFrame(\n",
    "        [evaluate_thresholds(t, y, probs) for t in np.arange(0, 1.01, 0.01)]\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_metrics_by_thresholds(y, probs, subplots=False):\n",
    "    evaluation = evaluate_thresholds(y, probs)\n",
    "    axs = (\n",
    "        evaluation.query(\"precision > 0\")\n",
    "        .set_index(\"threshold\")\n",
    "        .plot(subplots=subplots, sharex=True, sharey=True, figsize=(12, 8.5))\n",
    "    )\n",
    "    (axs[-1] if subplots else axs).set_xticks(np.arange(0, 1.05, 0.05))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_metrics_by_thresholds(y_train_1, logit.predict_proba(X_train_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Include sex in your model as well. Note that you'll need to encode this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.126353</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.050584</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.112718</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.937743</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130578</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>357</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0.579767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052521</td>\n",
       "      <td>Second</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.517510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026243</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>653</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0.452652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031630</td>\n",
       "      <td>Third</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.533074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105042</td>\n",
       "      <td>Second</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>589</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.452652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032523</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.361868</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030284</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.424125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031731</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex       age  sibsp  parch      fare  \\\n",
       "119           119         0       3  female  0.019455      4      2  0.126353   \n",
       "63             63         0       3    male  0.050584      3      2  0.112718   \n",
       "625           625         0       1    male  0.937743      0      0  0.130578   \n",
       "357           357         0       2  female  0.579767      0      0  0.052521   \n",
       "202           202         0       3    male  0.517510      0      0  0.026243   \n",
       "..            ...       ...     ...     ...       ...    ...    ...       ...   \n",
       "653           653         1       3  female  0.452652      0      0  0.031630   \n",
       "20             20         0       2    male  0.533074      0      0  0.105042   \n",
       "589           589         0       3    male  0.452652      0      0  0.032523   \n",
       "514           514         0       3    male  0.361868      0      0  0.030284   \n",
       "281           281         0       3    male  0.424125      0      0  0.031731   \n",
       "\n",
       "      class  embark_town  alone    C    Q    S  female  male  \n",
       "119   Third  Southampton      0  0.0  0.0  1.0     1.0   0.0  \n",
       "63    Third  Southampton      0  0.0  0.0  1.0     0.0   1.0  \n",
       "625   First  Southampton      1  0.0  0.0  1.0     0.0   1.0  \n",
       "357  Second  Southampton      1  0.0  0.0  1.0     1.0   0.0  \n",
       "202   Third  Southampton      1  0.0  0.0  1.0     0.0   1.0  \n",
       "..      ...          ...    ...  ...  ...  ...     ...   ...  \n",
       "653   Third   Queenstown      1  0.0  1.0  0.0     1.0   0.0  \n",
       "20   Second  Southampton      1  0.0  0.0  1.0     0.0   1.0  \n",
       "589   Third  Southampton      1  0.0  0.0  1.0     0.0   1.0  \n",
       "514   Third  Southampton      1  0.0  0.0  1.0     0.0   1.0  \n",
       "281   Third  Southampton      1  0.0  0.0  1.0     0.0   1.0  \n",
       "\n",
       "[590 rows x 16 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = train_scaled[[\"fare\", \"pclass\", \"age\", \"female\", \"male\"]]\n",
    "y_train_2 = train_scaled[[\"survived\"]]\n",
    "X_test_2= validate[[\"fare\", \"pclass\", \"age\", \"female\", \"male\"]]\n",
    "y_test_2= validate[[\"survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7762711864406779"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.819672131147541"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3 = train_scaled[[\"fare\", \"pclass\", \"age\", \"sibsp\"]]\n",
    "y_train_3 = train_scaled[[\"survived\"]]\n",
    "X_test_3= validate[[\"fare\", \"pclass\", \"age\", \"sibsp\"]]\n",
    "y_test_3= validate[[\"survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7016949152542373"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_train_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6557377049180327"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_test_3, y_test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Choose you best model and evaluate it on the test dataset. Is it overfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "\n",
    "X_train_2 = train_scaled[[\"fare\", \"pclass\", \"age\", \"female\", \"male\"]]\n",
    "y_train_2 = train_scaled[[\"survived\"]]\n",
    "X_test_2= test_scaled[[\"fare\", \"pclass\", \"age\", \"female\", \"male\"]]\n",
    "y_test_2= test_scaled[[\"survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7762711864406779"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7932960893854749"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the test with sex was our best performing model, we use it to compare it against our test data. In this case, we can see the model is not overfit, as the difference in accuracy between both is fairly small. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bonus How do different strategies for handling the missing values in the age column affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  deck  embark_town  alone  \n",
       "0        S  Third  None  Southampton      0  \n",
       "1        C  First     C    Cherbourg      0  \n",
       "2        S  Third  None  Southampton      1  \n",
       "3        S  First     C  Southampton      0  \n",
       "4        S  Third  None  Southampton      1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    714\n",
       "True     177\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.age.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(titanic, random_state = 123, train_size = .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    564\n",
       "True     148\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.age.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_avg_lookup = train.groupby([\"pclass\"]).age.agg(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"age\"] = train[\"age\"].fillna(train[\"pclass\"].map(group_avg_lookup))\n",
    "test[\"age\"] = test[\"age\"].fillna(test[\"pclass\"].map(group_avg_lookup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    712\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.age.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate = train_test_split(train, random_state =123, train_size= .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "\n",
    "X_train_4 = train[[\"fare\", \"pclass\", \"age\"]]\n",
    "y_train_4 = train[[\"survived\"]]\n",
    "X_test_4= validate[[\"fare\", \"pclass\", \"age\"]]\n",
    "y_test_4= validate[[\"survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_4, y_train_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7012302284710018"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_train_4, y_train_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6643356643356644"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_test_4, y_test_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without scaling the data, it seems the model actually performs about the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_scale_train = train[[\"age\", \"fare\"]]\n",
    "age_scale_test = test[[\"age\", \"fare\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, train_scaled, test_scaled = split_scale.min_max_scaler(age_scale_train, age_scale_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"age\"] = train_scaled[\"age\"]\n",
    "test[\"age\"] = test_scaled[\"age\"]\n",
    "train[\"fare\"] = train_scaled[\"fare\"]\n",
    "test[\"fare\"] = test_scaled[\"fare\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "\n",
    "X_train_5 = train[[\"fare\", \"pclass\", \"age\"]]\n",
    "y_train_5 = train[[\"survived\"]]\n",
    "X_test_5 = test[[\"fare\", \"pclass\", \"age\"]]\n",
    "y_test_5 = test[[\"survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_5, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7117750439367311"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_train_5, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7318435754189944"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_test_5, y_test_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even once the data is scaled, is seems to perform very similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.93217565, -0.83832614, -1.68659627]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the coefficients, we can see that they are all fairly similar, but age is definitively the most powerful indicator of suvivability at this point, and the higher the age, the lower the probability of survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bonus: How do different strategies for encoding sex affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(titanic, random_state = 123, train_size = .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>524</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>C</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>452</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7500</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.5000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>620</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>C</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "172           172         1       3  female   1.0      1      1  11.1333   \n",
       "524           524         0       3    male   NaN      0      0   7.2292   \n",
       "452           452         0       1    male  30.0      0      0  27.7500   \n",
       "170           170         0       1    male  61.0      0      0  33.5000   \n",
       "620           620         0       3    male  27.0      1      0  14.4542   \n",
       "\n",
       "    embarked  class  deck  embark_town  alone  \n",
       "172        S  Third  None  Southampton      0  \n",
       "524        C  Third  None    Cherbourg      1  \n",
       "452        C  First     C    Cherbourg      1  \n",
       "170        S  First     B  Southampton      1  \n",
       "620        C  Third  None    Cherbourg      0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = sklearn.impute.SimpleImputer(strategy = \"mean\")\n",
    "imputer.fit(train[[\"age\"]])\n",
    "train.age = imputer.transform(train[[\"age\"]])\n",
    "test.age = imputer.transform(test[[\"age\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "train[\"sex\"] = le.fit_transform(train.sex)\n",
    "test[\"sex\"] = le.transform(test.sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate = train_test_split(train, random_state = 123, train_size = .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7768014059753954"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "\n",
    "train_scaled\n",
    "\n",
    "X_train_7 = train[[\"fare\", \"pclass\", \"age\", \"sex\"]]\n",
    "y_train_7 = train[[\"survived\"]]\n",
    "X_test_7= validate[[\"fare\", \"pclass\", \"age\", \"sex\"]]\n",
    "y_test_7= validate[[\"survived\"]]\n",
    "\n",
    "logit.fit(X_train_7, y_train_7)\n",
    "\n",
    "logit.score(X_train_7, y_train_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8111888111888111"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_test_7, y_test_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00275126, -0.81985162, -0.01731668, -2.24534559]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a simple label encoder seemed to work the same as using a hot label encoder. The suprising part is that before, age was the most influencial coefficient, but once it is paired with sex, it seems that it becomes less relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. scikit-learn's LogisticRegression classifier is actually applying a regularization penalty to the coefficients by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "\n",
    "Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " When C = 0.01, then the accuracy score is 0.70\n",
      " When C = 0.1, then the accuracy score is 0.77\n",
      " When C = 1.0, then the accuracy score is 0.77\n",
      " When C = 10.0, then the accuracy score is 0.78\n",
      " When C = 100.0, then the accuracy score is 0.78\n",
      " When C = 1000.0, then the accuracy score is 0.78\n"
     ]
    }
   ],
   "source": [
    "C = .01\n",
    "c = 10\n",
    "X_train = train[[\"fare\", \"pclass\", \"sex\"]]\n",
    "y_train = train[[\"survived\"]]\n",
    "X_test = validate[[\"fare\", \"pclass\", \"sex\"]]\n",
    "y_test = validate[[\"survived\"]]\n",
    "accuracy_score = []\n",
    "\n",
    "\n",
    "for x in range(0,6):\n",
    "\n",
    "    \n",
    "    \n",
    "    logit = LogisticRegression(C=C)\n",
    "\n",
    "    logit.fit(X_train, y_train)\n",
    "\n",
    "    score = logit.score(X_train, y_train)\n",
    "    \n",
    "    accuracy_score.append(score)\n",
    "    \n",
    "    C *= c\n",
    "\n",
    "c = .001\n",
    "for i in range(1, 7):\n",
    "    print(f\" When C = {c * (10**i)}, then the accuracy score is {accuracy_score[i - 1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01008302 -0.21533558 -0.47912208]]\n",
      "[[ 7.47879367e-04 -9.40769809e-01 -2.57282771e+00]]\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(C=.01)\n",
    "\n",
    "logit.fit(X_train, y_train)\n",
    "coefficients = logit.coef_\n",
    "\n",
    "logit = LogisticRegression(C=1000)\n",
    "\n",
    "logit.fit(X_train, y_train)\n",
    "coefficients_2 = logit.coef_\n",
    "\n",
    "print(coefficients)\n",
    "print(coefficients_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
